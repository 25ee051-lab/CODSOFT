# ----------------------------------------
# HANDWRITTEN TEXT GENERATION (Student Touch Version)
# ----------------------------------------
# Idea: Train a Recurrent Neural Network (RNN) that learns handwriting strokes
# and then generates new "handwritten-like" text patterns.

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import matplotlib.pyplot as plt

# ----------------------------
# 1) Dataset
# ----------------------------
# Each handwriting sample is stored as a sequence of [dx, dy, pen_state]
# dx, dy = movement of the pen
# pen_state = 1 (pen down, drawing) or 0 (pen up, moving without drawing)

class StrokeDataset(Dataset):
    def __init__(self, npz_path, max_len=300):
        data = np.load(npz_path, allow_pickle=True)
        self.sequences = data['sequences']
        self.max_len = max_len

    def __len__(self):
        return len(self.sequences)

    def __getitem__(self, idx):
        seq = self.sequences[idx].astype(np.float32)
        if len(seq) > self.max_len:
            seq = seq[:self.max_len]
        # Input = strokes up to T-1, Target = strokes from 1..T
        x = seq[:-1]
        y = seq[1:]
        return torch.from_numpy(x), torch.from_numpy(y)

# ----------------------------
# 2) Model: Simple RNN (LSTM)
# ----------------------------
# The RNN learns sequences of strokes.
# For simplicity, we predict the next stroke directly.

class HandwritingRNN(nn.Module):
    def __init__(self, input_dim=3, hidden_dim=128, num_layers=2):
        super().__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, input_dim)  # predict [dx, dy, pen_state]

    def forward(self, x, h=None):
        y, h_next = self.lstm(x, h)
        out = self.fc(y)
        return out, h_next

# ----------------------------
# 3) Training Loop
# ----------------------------
# We train the model to minimize mean squared error between predicted strokes and actual strokes.

def train_model(npz_path, epochs=10, batch_size=32, lr=1e-3, device='cpu'):
    dataset = StrokeDataset(npz_path)
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

    model = HandwritingRNN().to(device)
    opt = torch.optim.Adam(model.parameters(), lr=lr)

    for ep in range(epochs):
        model.train()
        total_loss = 0.0
        for X, Y in loader:
            X, Y = X.to(device), Y.to(device)
            out, _ = model(X)
            loss = F.mse_loss(out, Y)

            opt.zero_grad()
            loss.backward()
            opt.step()
            total_loss += loss.item()

        print(f"Epoch {ep+1}/{epochs} | Loss: {total_loss/len(loader):.4f}")

    return model

# ----------------------------
# 4) Sampling and Rendering
# ----------------------------
# After training, we can generate new handwriting strokes
# and render them as lines on a canvas.

def render_strokes(strokes, title="Generated Handwriting"):
    x, y = [0.0], [0.0]
    for dx, dy, pen in strokes:
        x.append(x[-1] + dx)
        y.append(y[-1] + dy)

    plt.figure(figsize=(6, 4))
    for i in range(1, len(x)):
        if strokes[i-1][2] > 0.5:  # pen down
            plt.plot([x[i-1], x[i]], [y[i-1], y[i]], color='black')
    plt.gca().invert_yaxis()
    plt.axis('off')
    plt.title(title)
    plt.show()
